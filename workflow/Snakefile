from os.path import join, dirname


# Sample manifest dict.
MANIFEST = config["samples"]

# CDR and other
WINDOW = config["window_size"]
ALR_THRESHOLD = config.get("alr_threshold", 100000)
BP_MERGE = config.get("bp_merge")
BP_EDGE = config.get("bp_edge", 500_000)
EXTEND_EDGES_STD = config.get("extend_edges_std", -1)
BP_ALR_MERGE = config.get("bp_alr_merge", 1000)
HEIGHT_THRESHOLD = config.get("height_perc_valley_threshold", 0.34)
PROM_THRESHOLD = config.get("prom_perc_valley_threshold", 0.3)
EDGE_HEIGHT_HEURISTIC = config.get("edge_height_heuristic", "min")
BASELINE_AVG_METHYL = config.get("baseline_avg_methyl", 0.4)
RESTRICT_ALR = config.get("restrict_alr", True)
OVERLAP_OPACITY = config.get("overlap_opacity", 0.34)
CONTAINER = config.get("container", None)

# Workflow params
OUTPUT_DIR = config.get("output_dir", "results")
LOG_DIR = config.get("log_dir", "logs")
BMK_DIR = config.get("benchmark_dir", "benchmarks")

if CONTAINER:

    containerized: CONTAINER


wildcard_constraints:
    sample="|".join(MANIFEST.keys()),
    fname=r"[^\/]*",
    ctg=r"[^\/]*",


def convert_seqkit_coord_to_tsv(wc) -> str:
    # seqkit split converts ':' to '__'
    chrom, coords = wc.fname.split("__")
    start, end = coords.split("-")
    return f"{chrom}\\t{start}\\t{end}\\n"


###
# Subset fasta: Extracts subsequence from target bed so can run RM per contig.
###


checkpoint subset_fasta:
    input:
        fasta=lambda wc: MANIFEST[wc.sample]["fasta"],
        bed=lambda wc: MANIFEST[wc.sample]["regions"],
    output:
        fasta_fofn=join(OUTPUT_DIR, "fasta", "{sample}_subset.fofn"),
    log:
        join(LOG_DIR, "subset_fasta_{sample}.log"),
    resources:
        mem=8,
        hrs=1,
    params:
        fasta_dir=lambda wc, output: os.path.splitext(output.fasta_fofn)[0],
    threads: 1
    conda:
        "envs/tools.yaml"
    shell:
        """
        # Split fasta.
        {{ bedtools getfasta -fi {input.fasta} -bed {input.bed} | \
        seqkit split -i --by-id-prefix "" -O {params.fasta_dir} ;}} 2> {log}
        # Index all fasta files and write to fofn
        find {params.fasta_dir} -name "*.fasta" -print0 | \
            while IFS= read -r -d '' fasta; do
                samtools faidx "${{fasta}}"
                echo "${{fasta}}" >> {output.fasta_fofn}
            done
        """


###
# Get methylation information.
###


rule get_methylation_bed:
    input:
        ref=lambda wc: MANIFEST[wc.sample]["fasta"],
        bam=lambda wc: MANIFEST[wc.sample]["bam"],
        region=lambda wc: MANIFEST[wc.sample]["regions"],
    output:
        methyl_bed=join(OUTPUT_DIR, "bed", "{sample}_methyl.bed"),
    log:
        join(LOG_DIR, "get_methylation_bed_{sample}.log"),
    benchmark:
        join(BMK_DIR, "get_methylation_bed_{sample}.tsv")
    params:
        preset="traditional",
        ref=lambda wc, input: (
            f"<(zcat {input.ref})" if str(input.ref).endswith(".gz") else input.ref
        ),
    threads: 4
    resources:
        mem=8,
        hrs=1,
    conda:
        "envs/tools.yaml"
    shell:
        """
        samtools index {input.bam} 2> {log}
        modkit pileup {input.bam} {output.methyl_bed} \
        --include-bed <(cut -f 1-3 {input.region}) \
        --threads {threads} \
        --ref {params.ref} \
        --preset {params.preset} 2>> {log}
        """


###
# Rename fasta to avoid RepeatMasker ID limit.
###
rule rename_fasta:
    input:
        fasta=join(OUTPUT_DIR, "fasta", "{sample}_subset", "{fname}.fasta"),
        fasta_idx=join(OUTPUT_DIR, "fasta", "{sample}_subset", "{fname}.fasta.fai"),
    output:
        renamed_fasta=temp(
            join(OUTPUT_DIR, "fasta", "{sample}_{fname}_subset_renamed.fasta")
        ),
        renamed_fasta_idx=temp(
            join(OUTPUT_DIR, "fasta", "{sample}_{fname}_subset_renamed.fasta.fai")
        ),
        rename_key=temp(
            join(OUTPUT_DIR, "fasta", "{sample}_{fname}_subset_rename_key.tsv")
        ),
    log:
        join(LOG_DIR, "rename_fasta_{sample}_{fname}.log"),
    conda:
        "envs/tools.yaml"
    shell:
        """
        seqtk rename {input.fasta} "seq" > {output.renamed_fasta} 2> {log}
        samtools faidx {output.renamed_fasta} 2>> {log}
        paste -d'\\t' <(cut -f 1 {output.renamed_fasta_idx}) <(cut -f 1 {input.fasta_idx}) > {output.rename_key} 2>> {log}
        """


###
# run_rm: Runs repeatmasker on the extracted subsequence fasta from rule subset_fasta
###


rule run_rm:
    input:
        fasta=rules.rename_fasta.output.renamed_fasta,
    output:
        rm_out=join(
            OUTPUT_DIR,
            "rm",
            "{sample}_{fname}_subset_renamed.fasta.out",
        ),
    log:
        join(LOG_DIR, "run_rm_{sample}_{fname}.log"),
    benchmark:
        join(BMK_DIR, "run_rm_{sample}_{fname}.tsv")
    params:
        engine="rmblast",
        species=config.get("species", "human"),
        output_dir=lambda wc, output: os.path.dirname(str(output)),
    resources:
        mem=8,
        hrs=12,
    threads: 12
    conda:
        "envs/tools.yaml"
    shell:
        """
        RepeatMasker \
        -engine {params.engine} \
        -species {params.species} \
        -dir {params.output_dir} \
        -qq \
        -pa {threads} \
        {input.fasta} > {log}
        """


###
# Calculates mean frequency in windows/bins of the methylation tsv over the target region
###


rule intersect_methyl_bed:
    input:
        methylation_tsv=rules.get_methylation_bed.output,
    output:
        # To make wildcard filename distinct, use - instead of _.
        methyl_bed=temp(join(OUTPUT_DIR, "bed", "{sample}-{fname}_methyl.bed")),
    params:
        bed_tsv=convert_seqkit_coord_to_tsv,
    log:
        join(LOG_DIR, "intersect_methyl_bed_{sample}_{fname}.log"),
    conda:
        "envs/tools.yaml"
    shell:
        """
        bedtools intersect -a {input.methylation_tsv} -b <(printf "{params.bed_tsv}") > {output.methyl_bed} 2> {log}
        """


rule calc_windows:
    input:
        script=workflow.source_path("scripts/calculate_windows.py"),
        methylation_tsv=rules.intersect_methyl_bed.output,
    output:
        binned_freq=temp(join(OUTPUT_DIR, "bed", "{sample}_{fname}_binned_freq.bed")),
    log:
        join(LOG_DIR, "calc_windows_{sample}_{fname}.log"),
    benchmark:
        join(BMK_DIR, "calc_windows_{sample}_{fname}.tsv")
    threads: 1
    resources:
        mem=30,
        hrs=1,
    threads: 1
    conda:
        "envs/python.yaml"
    params:
        window_size=WINDOW,
        bed_tsv=convert_seqkit_coord_to_tsv,
    shell:
        """
        python {input.script} \
        --target_bed <(printf "{params.bed_tsv}") \
        --methylation_tsv {input.methylation_tsv} \
        --window_size {params.window_size} \
        -p {threads} > {output} 2> {log}
        """


###
# Format RM: Converts Repeatmasker output to bedfile and extracts only ALR annotations
# Otherwise, use user-provided RepeatMasker
###


rule intersect_user_rm_output:
    input:
        rm_out=lambda wc: (
            MANIFEST[wc.sample]["repeatmasker"]
            if MANIFEST[wc.sample].get("repeatmasker")
            else []
        ),
    output:
        rm_bed=temp(join(OUTPUT_DIR, "bed", "{sample}_{fname}_rm_user.bed")),
    params:
        bed_tsv=convert_seqkit_coord_to_tsv,
    log:
        join(LOG_DIR, "intersect_user_rm_output_{sample}_{fname}.log"),
    conda:
        "envs/tools.yaml"
    shell:
        """
        bedtools intersect -a {input.rm_out} -b <(printf "{params.bed_tsv}") > {output.rm_bed} 2> {log}
        """


rule format_RM:
    input:
        script=workflow.source_path("scripts/reformat_rm.py"),
        rm_out=rules.run_rm.output.rm_out,
        rename_key=rules.rename_fasta.output.rename_key,
    output:
        rm_bed=temp(join(OUTPUT_DIR, "bed", "{sample}_{fname}_rm.bed")),
    log:
        join(LOG_DIR, "format_filter_RM_{sample}_{fname}.log"),
    resources:
        mem=8,
        hrs=1,
    conda:
        "envs/python.yaml"
    threads: 1
    shell:
        """
        python {input.script} \
        -i <(awk -v OFS="\\t" '{{$1=$1; print}}' {input.rm_out}) \
        -r {input.rename_key} > {output.rm_bed} 2> {log}
        """


###
# Intersect RM: Merges repeatmasker bed file with 500bp slop, and only keeps those above the ALR Threshold
#               Intersects merged ALR bed file with binned methylation frequency bedfile
###


rule intersect_RM:
    input:
        repeat_masker=lambda wc: (
            rules.intersect_user_rm_output.output
            if MANIFEST[wc.sample].get("repeatmasker")
            else rules.format_RM.output
        ),
        binned_freq=rules.calc_windows.output,
    output:
        intersect_bed=temp(join(OUTPUT_DIR, "bed", "{sample}_{fname}_intersect.bed")),
    log:
        join(LOG_DIR, "intersect_RM_{sample}_{fname}.log"),
    benchmark:
        join(BMK_DIR, "intersect_RM_{sample}_{fname}.tsv")
    resources:
        mem=8,
        hrs=1,
    params:
        alr_threshold=ALR_THRESHOLD,
        bp_alr_merge=BP_ALR_MERGE,
    threads: 1
    conda:
        "envs/tools.yaml"
    shell:
        """
        {{ bedtools merge -i <(grep ALR/Alpha {input.repeat_masker} | sort -k1,1 -k2,2n) -d {params.bp_alr_merge} | \
        awk '{{if ($3-$2 > {params.alr_threshold}) print}}' | \
        bedtools intersect -a {input.binned_freq} -b - -f 1 -wa -u ;}} > {output.intersect_bed} 2>> {log}
        """


def bed_files(wc):
    fofn = checkpoints.subset_fasta.get(**wc).output.fasta_fofn
    fnames = []
    with open(fofn) as fh:
        for file in fh:
            file = file.strip()
            fname, ext = os.path.splitext(os.path.basename(file))
            fnames.append(fname)

    rm_out = (
        expand(rules.format_RM.output, sample=wc.sample, fname=fnames)
        if not MANIFEST[wc.sample].get("repeatmasker")
        else expand(
            rules.intersect_user_rm_output.output, sample=wc.sample, fname=fnames
        )
    )
    if RESTRICT_ALR:
        return {
            "rm": rm_out,
            "methyl_rgn": expand(
                rules.intersect_RM.output, sample=wc.sample, fname=fnames
            ),
            "methyl": expand(rules.calc_windows.output, sample=wc.sample, fname=fnames),
        }
    else:
        return {
            "rm": rm_out,
            "methyl_rgn": expand(
                rules.calc_windows.output, sample=wc.sample, fname=fnames
            ),
            "methyl": expand(rules.calc_windows.output, sample=wc.sample, fname=fnames),
        }


rule aggregate_bed_files:
    input:
        unpack(bed_files),
    output:
        rm_bed=join(OUTPUT_DIR, "bed", "{sample}_merged_rm.bed"),
        methyl_bed=join(OUTPUT_DIR, "bed", "{sample}_merged_methyl.bed"),
        methyl_bed_all=join(OUTPUT_DIR, "bed", "{sample}_merged_methyl_all.bed"),
    params:
        rm=lambda wc, input: input.rm if input.rm else "<(echo '')",
        methyl=lambda wc, input: input.methyl if input.rm else "<(echo '')",
        methyl_rgn=lambda wc, input: input.methyl_rgn
        if input.methyl_rgn
        else "<(echo '')",
    shell:
        """
        cat {params.rm} > {output.rm_bed}
        cat {params.methyl_rgn} > {output.methyl_bed}
        cat {params.methyl} > {output.methyl_bed_all}
        """


checkpoint call_cdrs:
    input:
        script=workflow.source_path("scripts/cdr_finder.py"),
        methyl_bed=rules.aggregate_bed_files.output.methyl_bed,
        override_chrom_params=lambda wc: (
            MANIFEST[wc.sample]["override_chrom_params"]
            if MANIFEST[wc.sample].get("override_chrom_params", [])
            else []
        ),
    output:
        cdrs=join(OUTPUT_DIR, "bed", "{sample}_CDR.bed"),
    log:
        join(LOG_DIR, "call_cdrs_{sample}.log"),
    benchmark:
        join(BMK_DIR, "call_cdrs_{sample}.tsv")
    resources:
        mem=8,
        hrs=1,
    params:
        bp_merge=f"--bp_merge {BP_MERGE}" if BP_MERGE else "",
        bp_edge=BP_EDGE,
        thr_prom_perc_valley=(
            f"--thr_prom_perc_valley {PROM_THRESHOLD}" if PROM_THRESHOLD else ""
        ),
        edge_height_heuristic=EDGE_HEIGHT_HEURISTIC,
        extend_edges_std=(
            f"--extend_edges_std {EXTEND_EDGES_STD}"
            if isinstance(EXTEND_EDGES_STD, int)
            else ""
        ),
        thr_height_perc_valley=HEIGHT_THRESHOLD,
        override_chrom_params=lambda wc, input: (
            f"--override_chrom_params {input.override_chrom_params}"
            if input.override_chrom_params
            else ""
        ),
        baseline_avg_methyl=(
            f"--baseline_avg_methyl {BASELINE_AVG_METHYL}"
            if BASELINE_AVG_METHYL
            else ""
        ),
    conda:
        "envs/python.yaml"
    threads: 1
    shell:
        """
        python {input.script} \
        -i {input.methyl_bed} \
        --thr_height_perc_valley {params.thr_height_perc_valley} \
        --bp_edge {params.bp_edge} \
        --edge_height_heuristic {params.edge_height_heuristic} \
        {params.bp_merge} \
        {params.thr_prom_perc_valley} \
        {params.extend_edges_std} \
        {params.override_chrom_params} \
        {params.baseline_avg_methyl} > {output} 2> {log}
        """


rule format_files_for_cenplot:
    input:
        script=workflow.source_path("scripts/format_files_for_cenplot.py"),
        plot_layout=workflow.source_path("scripts/plot_layout.toml"),
        binned_freq_bed=rules.aggregate_bed_files.output.methyl_bed_all,
        cdr_bed=rules.call_cdrs.output,
        rm_bed=rules.aggregate_bed_files.output.rm_bed,
    output:
        cdr_bed=join(OUTPUT_DIR, "bed", "{sample}", "{ctg}", "cdr.bed"),
        cov_bed=join(OUTPUT_DIR, "bed", "{sample}", "{ctg}", "cov.bed"),
        methyl_cov_bed=join(OUTPUT_DIR, "bed", "{sample}", "{ctg}", "methyl_cov.bed"),
        methyl_avg_cov_bed=join(
            OUTPUT_DIR, "bed", "{sample}", "{ctg}", "methyl_avg_cov.bed"
        ),
        rm_bed=join(OUTPUT_DIR, "bed", "{sample}", "{ctg}", "rm.bed"),
        plot_layout=join(OUTPUT_DIR, "plot", "{sample}", "{ctg}_plot_layout.toml"),
    conda:
        "envs/python.yaml"
    params:
        outdir=lambda wc, output: dirname(dirname(output.cdr_bed)),
        esc_outdir=lambda wc, output: dirname(output.cdr_bed).replace("/", "\\/"),
        overlap_opacity=OVERLAP_OPACITY,
    log:
        join(LOG_DIR, "format_files_for_cenplot_{sample}_{ctg}.log"),
    shell:
        """
        python {input.script} \
        --ctg {wildcards.ctg} \
        --bed_binned_freq {input.binned_freq_bed} \
        --bed_cdr {input.cdr_bed} \
        --bed_rm {input.rm_bed} \
        --outdir {params.outdir} 2> {log}
        # Replace outdir format string with outdir
        sed -e 's/{{outdir}}/{params.esc_outdir}/g' -e 's/"{{overlap_opacity}}"/{params.overlap_opacity}/g' {input.plot_layout} > {output.plot_layout} 2> {log}
        """


rule plot_cdr:
    input:
        plot_layout=rules.format_files_for_cenplot.output.plot_layout,
    output:
        join(OUTPUT_DIR, "plot", "{sample}", "{ctg}.png"),
    log:
        join(LOG_DIR, "plot_cdr_{sample}_{ctg}.log"),
    benchmark:
        join(BMK_DIR, "plot_cdr_{sample}_{ctg}.tsv")
    params:
        outdir=lambda wc, output: dirname(output[0]),
    resources:
        mem=8,
        hrs=1,
    conda:
        "envs/python.yaml"
    shell:
        """
        cenplot draw -t {input.plot_layout} -c {wildcards.ctg} -d {params.outdir} -p 1 2> {log}
        """


def all_cdr_plots(wc):
    _ = checkpoints.call_cdrs.get(**wc).output
    # Plot all contigs
    intersect_bed = expand(rules.call_cdrs.input.methyl_bed, sample=wc.sample)[0]
    ctgs = set()
    with open(intersect_bed, "rt") as fh:
        for line in fh:
            ctg, *_ = line.strip().split("\t")
            ctgs.add(ctg)

    return expand(rules.plot_cdr.output, sample=wc.sample, ctg=ctgs)


rule cdr_plots:
    input:
        all_cdr_plots,
    output:
        touch(join(OUTPUT_DIR, "plot", "{sample}.done")),


rule cleanup_fasta:
    input:
        chkpts=[
            expand(rules.call_cdrs.output, sample=MANIFEST.keys()),
            expand(rules.cdr_plots.output, sample=MANIFEST.keys()),
        ],
        fasta_fofn=rules.subset_fasta.output,
    output:
        touch(join(OUTPUT_DIR, "fasta", "{sample}_cleanup.done")),
    shell:
        """
        # Remove fasta and index
        awk '{{ print $1; print $1".fai" }}' {input.fasta_fofn} | xargs rm -f
        """


rule all:
    input:
        expand(rules.call_cdrs.output, sample=MANIFEST.keys()),
        expand(rules.cdr_plots.output, sample=MANIFEST.keys()),
        expand(rules.cleanup_fasta.output, sample=MANIFEST.keys()),
    default_target: True
